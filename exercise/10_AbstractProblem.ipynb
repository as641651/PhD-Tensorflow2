{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective function : \n",
    "\n",
    ">$min_{\\Phi} \\quad L(\\mathbf{y}, \\mathbf{f}_{\\Phi})$\n",
    "\n",
    "Where,\n",
    "\n",
    "> $\\mathbf{y} \\in \\mathbb{R}^{N}\\text{ is a vector containing N measurements}$\n",
    "\n",
    "> $\\mathbf{f}_{\\Phi} \\text{ is a model function which provides estimates}$\n",
    "\n",
    "> Loss function  $L \\in \\mathbb{R}$\n",
    "\n",
    "$\\Phi \\in \\mathbb{R}^{K} \\text{ are the parameters of the model which minimizes some loss function } L \\text { ( and K is the total number of parameters)}$ \n",
    "\n",
    "Iterative solution for $\\Phi$\n",
    "\n",
    "\n",
    "> $\\Phi_{t+1} = \\Phi_t + update(\\frac{\\partial L}{\\partial \\Phi}) \\qquad \\Phi_t, \\frac{\\partial L}{\\partial \\Phi} \\in \\mathbb{R}^{K}$\n",
    "\n",
    "Different iterative optimization techniques can be realized based on the choice of **update** function.\n",
    "\n",
    "Eg, for Stochastic Gradient descent,\n",
    "\n",
    "> $update(\\frac{\\partial L}{\\partial \\Phi}) = \\gamma \\frac{\\partial L}{\\partial \\Phi} \\qquad \\gamma \\in \\mathbb{R} \\text{ is the learning rate}$\n",
    "\n",
    "Based on the choice of **L** and **f**, we can realize solutions to a variety of problems. Some examples are listed below, \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Some choices of Loss function L\n",
    "\n",
    "### 1. Joint Quantile Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a set of quantiles, $Q \\in \\{ q_1, q_2, ..., q_M \\}$\n",
    "\n",
    "$L(\\mathbf{y}, \\mathbf{f}) = \\sum_q \\sum_{i=y_i < \\mathbf{f}_q} (1-q)|y_i - \\mathbf{f}_q | + \\sum_{i=y_i \\ge \\mathbf{f}_q} (q)|y_i - \\mathbf{f}_q | \\qquad q \\in \\{1,2,..,M\\} \\qquad i \\in \\{1,2,..,N\\}$\n",
    "\n",
    "\n",
    "$  \\mathbf{f}(x, \\Phi ) \\in \\mathbb{R}^{M} $\n",
    "\n",
    "Where, \n",
    "\n",
    "> M is the number of quantiles to be realized\n",
    "\n",
    "> **x** is the feature given as input to the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Independent Quantile Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a set of quantiles, $Q \\in \\{ q_1, q_2, ..., q_M \\}$\n",
    "\n",
    "$L_q(\\mathbf{y}, \\mathbf{f}) = \\sum_{i=y_i < \\mathbf{f}_q} (1-q)|y_i - \\mathbf{f}_q | + \\sum_{i=y_i \\ge \\mathbf{f}_q} (q)|y_i - \\mathbf{f}_q | \\qquad i \\in \\{1,2,..,N\\} $\n",
    "\n",
    "\n",
    "$  \\mathbf{f}_q(x, \\Phi ) \\in \\mathbb{R} $\n",
    "\n",
    "Solve **M** optimization problems for $\\{L_q, \\mathbf{f}_q\\} \\qquad q \\in \\{1,2,..,M\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Least Square Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f** approximates the **mean**\n",
    "\n",
    "$L(\\mathbf{y}, \\mathbf{f}) = \\sum_{i} (y_i - \\mathbf{f})^{2} \\qquad i \\in \\{1,2,..,N\\}$\n",
    "\n",
    "\n",
    "$  \\mathbf{f}(x, \\Phi ) \\in \\mathbb{R} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Weighted Least Squares\n",
    "\n",
    "(Solution for sampling bias, when we want to have more weights for data points at ridge points)\n",
    "\n",
    "$L(\\mathbf{y}, \\mathbf{f}) = \\sum_{i} w_i(y_i - \\mathbf{f})^{2} \\qquad i \\in \\{1,2,..,N\\}$\n",
    "\n",
    "\n",
    "$  \\mathbf{f}(x, \\Phi ) \\in \\mathbb{R} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some choices of model function f\n",
    "\n",
    "### 1. Multi Layer Perceptron\n",
    "\n",
    "To set up a multilayer perceptron, we should fix the following hyper parameters : \n",
    "\n",
    "> 1. **J** : The number of layers in a multi layer perceptron.\n",
    "\n",
    "> 2. $L_j \\text{ : the number of hidden units of a multi layer perceptron in every layer j}$\n",
    "\n",
    "Then our model function will be, \n",
    "\n",
    "> $\\mathbf{f}(x, \\Phi)= \\mathbf{W}_J . a(\\mathbf{z_{J}}) \\qquad  \\Phi = \\{W_1, ..., W_j\\} \\qquad \\mathbf{z}_1 = x$ \n",
    "\n",
    "Where,\n",
    "\n",
    "> $\\mathbf{z_j} = \\mathbf{W}_{j-1}.a(\\mathbf{z}_{j-1}) \\qquad j \\in \\{2,...,J\\}$\n",
    "\n",
    "> $W_j \\in \\mathbb{R}^{L_j \\times L_{(j-1)}}$\n",
    "\n",
    "> Activation function $ a : \\mathbb{R}^{L_j} \\to \\mathbb{R}^{L_j}$\n",
    "\n",
    "> $\\mathbf{f} \\in \\mathbb{R}^{L_{\\mathbf{J}}} \\qquad x \\in \\mathbb{R}^{L_1}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
